{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures for\n",
    "\n",
    "# Predicting competition results from growth curves\n",
    "\n",
    "by Yoav Ram, Eynat Deluss-Gur, Uri Obolski, Maayan Bibi, Judith Berman, and Lilach Hadany.\n",
    "\n",
    "*A manuscript in preparation.*\n",
    "\n",
    "#### Preprint: \n",
    "\n",
    "Ram et al. (2015) Predicting competition results from growth curves. bioRxiv doi: [10.1101/022640](http://biorxiv.org/content/early/2015/07/23/022640).\n",
    "\n",
    "#### Notebook\n",
    "This Jupyter notebook is an electronic supplementry material of the article.\n",
    "\n",
    "The notebook **will be available** available at https://github.com/yoavram/curveball_ms/blob/master/supp.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import pkg_resources\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.warnings.simplefilter('ignore', FutureWarning)\n",
    "plt.warnings.simplefilter('ignore', DeprecationWarning)\n",
    "plt.rcParams['mathtext.default'] = 'regular'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from scipy.integrate import odeint\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='paper', font_scale=2, palette='Set1')\n",
    "red, blue, green = sns.color_palette('Set1', 3)\n",
    "width, height = plt.rcParams['figure.figsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curveball,  0.2.3+7.g20f23ea.dirty\n",
      "Working folder: D:\\Dropbox\\ex silico\n"
     ]
    }
   ],
   "source": [
    "import curveball\n",
    "import curveball.scripts.cli\n",
    "print('Curveball, ', curveball.__version__)\n",
    "folder = os.path.join('D:\\\\', 'Dropbox', 'ex silico')\n",
    "print('Working folder:', folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fig_xlabel(label):\n",
    "    fig.text(0.5, 0, label, horizontalalignment='center', verticalalignment='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "datasets = collections.OrderedDict()\n",
    "datasets['2015-11-18'] = {\n",
    "    'plate_file': os.path.join(folder, 'tecan', 'plate_181115.csv'),\n",
    "    'OD_file': os.path.join(folder, 'tecan', 'Yoav_181115.xlsx'),\n",
    "    'max_time': 12,\n",
    "    'bad_wells': ['B2','E1','C4','A2'] + # G outliers\n",
    "                 ['H9','C11','A10','C12','A11','A9','C9','H11'] + # R outliers\n",
    "                 ['E5','E8','H6','H8','H7','H5'], # RG outliers\n",
    "    'flow_mean_file': os.path.join(folder, 'flow', 'mean_df_2015-11-18.csv'),\n",
    "    'flow_std_file': os.path.join(folder, 'flow', 'std_df_2015-11-18.csv'),\n",
    "    'lag': True\n",
    "}\n",
    "datasets['2015-12-14'] = {\n",
    "    'plate_file': os.path.join(folder, 'tecan', 'plate_141215.csv'),\n",
    "    'OD_file': os.path.join(folder, 'tecan', 'Yoav_141215.xlsx'),\n",
    "    'max_time': 7,\n",
    "    'bad_wells': ['{}{}'.format(c, i) for c in 'ABCDEFGH' for i in range(4, 8)] + # used for flow samples\n",
    "                 ['B10','B11','C10','A11','E11','A12'] + # red outliers\n",
    "                 ['D8','H8'], # RG outliers\n",
    "    'flow_mean_file': os.path.join(folder, 'flow', 'mean_df_2015-12-14.csv'),\n",
    "    'flow_std_file': os.path.join(folder, 'flow', 'std_df_2015-12-14.csv'),\n",
    "    'lag': False\n",
    "}\n",
    "datasets['2015-12-23'] = {\n",
    "    'plate_file': os.path.join(folder, 'tecan', 'plate_231215.csv'),\n",
    "    'OD_file': os.path.join(folder, 'tecan', 'Yoav_231215.xlsx'),\n",
    "    'max_time': 8,\n",
    "    'bad_wells': ['{}{}'.format(c, i) for c in 'ABCDEFGH' for i in range(4, 8)] + # used for flow samples\n",
    "                 ['A1'] + # G outliers\n",
    "                 ['D11','A11','A12','D10','H10','C10'] + # R outliers\n",
    "                 ['A8','A9', 'B8', 'B9', 'C9', 'D8', 'H8'], # RG outliers\n",
    "    'flow_mean_file': os.path.join(folder, 'flow', 'mean_df_2015-12-23.csv'),\n",
    "    'flow_std_file': os.path.join(folder, 'flow', 'std_df_2015-12-23.csv'),\n",
    "    'lag': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ds in datasets.values():\n",
    "    ds['plate'] = pd.read_csv(ds['plate_file'])\n",
    "    ds['df'] = curveball.ioutils.read_tecan_xlsx(ds['OD_file'], plate=ds['plate'], max_time=ds['max_time'])\n",
    "    ds['df'] = ds['df'][~ds['df'].Well.isin(ds['bad_wells'])]\n",
    "    ds['dfG'] = ds['df'][ds['df'].Strain.str.contains('GFP')]\n",
    "    ds['dfR'] = ds['df'][ds['df'].Strain.str.contains('RFP')]\n",
    "    ds['dfRG'] = ds['df'][ds['df'].Strain=='mixed']\n",
    "    ds['RG0_mean'] = ds['dfRG'][(ds['dfRG'].Time==ds['dfRG'].Time.min())].OD.mean()\n",
    "    ds['RG_time'] = ds['dfRG'].Time.unique()\n",
    "    ds['RG_mean'] = ds['dfRG'].groupby(by='Time').OD.mean()\n",
    "    ds['RG_std'] = ds['dfRG'].groupby(by='Time').OD.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = len(datasets)\n",
    "fig, ax = plt.subplots(1, cols, sharex=False, sharey=True, figsize=(width * cols, height))\n",
    "for i,(name, ds) in enumerate(datasets.items()):\n",
    "    curveball.plots.tsplot(ds['df'], ax=ax[i])\n",
    "    ax[i].set(title=name, xlabel='')\n",
    "    if i == 0:\n",
    "        ax[i].set(ylabel=r'Density ($OD_{600}$)')        \n",
    "    else:\n",
    "        ax[i].set(ylabel='')\n",
    "        ax[i].legend().set_visible(False)\n",
    "fig_xlabel('Time (hr)')\n",
    "#fig.savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ds in datasets.values():\n",
    "    param_fix = {'y0', 'K'}\n",
    "    param_guess = None\n",
    "    if not ds['lag']:\n",
    "        param_fix.add('q0')\n",
    "        param_fix.add('v')\n",
    "        param_guess = {'q0': np.inf, 'v': np.inf}\n",
    "    models_G = curveball.models.fit_model(ds['dfG'], param_fix=param_fix, param_guess=param_guess, PRINT=False, PLOT=False)\n",
    "    ds['model_G'] = models_G[0]\n",
    "    models_R = curveball.models.fit_model(ds['dfR'], param_fix=param_fix, param_guess=param_guess, PRINT=False, PLOT=False)\n",
    "    ds['model_R'] = models_R[0]\n",
    "    models_RG = curveball.models.fit_model(ds['dfRG'], param_fix=param_fix, param_guess=param_guess, PRINT=False, PLOT=False)\n",
    "    ds['model_RG'] = models_RG[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = len(datasets)\n",
    "fig, ax = plt.subplots(1, cols, sharex=False, sharey=True, figsize=(width * cols, height))\n",
    "for i,(name, ds) in enumerate(datasets.items()):\n",
    "    ds['model_G'].plot_fit(ax=ax[i], fit_kws={'color':green}, data_kws={'color':green,'alpha':0.5, 'marker':'.'}, init_kws={'ls':''})\n",
    "    ds['model_R'].plot_fit(ax=ax[i], fit_kws={'color':red}, data_kws={'color':red, 'alpha':0.5, 'marker':'.'}, init_kws={'ls':''})\n",
    "    ds['model_RG'].plot_fit(ax=ax[i], fit_kws={'color':blue}, data_kws={'color':blue,'alpha':0.5, 'marker':'.'}, init_kws={'ls':''})\n",
    "    \n",
    "    ax[i].set(title=name, xlabel='')\n",
    "    if i == 0:\n",
    "        ax[i].set(ylabel=r'Density ($OD_{600}$)')\n",
    "    else:\n",
    "        ax[i].set(ylabel='')\n",
    "    ax[i].legend().set_visible(False)\n",
    "fig_xlabel('Time (hr)')\n",
    "fig.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "def smooth(x, y, **kwargs):\n",
    "    if 'return_sorted' not in kwargs:\n",
    "        kwargs['return_sorted'] = False\n",
    "    if 'missing' not in kwargs:\n",
    "        kwargs['missing'] = 'raise'\n",
    "    yhat = lowess(y, x, **kwargs)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expnential_model(mGreen, mRed, frac_green=0.3, frac_red=0.3, di=2, \n",
    "                     colors=sns.color_palette('Set1', 3)[::2], ax=None, PLOT=False):\n",
    "    G = np.unique(mGreen.best_fit)\n",
    "    tG = np.unique(mGreen.userkws['t'])\n",
    "    dt = (tG.max() - tG.min())/G.size\n",
    "    dGdt = np.gradient(G, dt)\n",
    "\n",
    "    R = np.unique(mRed.best_fit)\n",
    "    tR = np.unique(mRed.userkws['t'])\n",
    "    dt = (tR.max() - tR.min())/R.size\n",
    "    dRdt = np.gradient(R, dt)\n",
    "\n",
    "    dGdt_smooth = smooth(tG, dGdt, frac=frac_green)\n",
    "    dRdt_smooth = smooth(tR, dRdt, frac=frac_red)\n",
    "    \n",
    "    \n",
    "    imaxG = dGdt_smooth.argmax()\n",
    "    slopeG, interceptG, _, _, _ = linregress(tG[imaxG-di:imaxG+di], np.log(G[imaxG-di:imaxG+di]))\n",
    "    imaxR = dRdt_smooth.argmax()\n",
    "    slopeR, interceptR, _, _, _ = linregress(tR[imaxR-di:imaxR+di], np.log(R[imaxR-di:imaxR+di]))\n",
    "\n",
    "    if PLOT:\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        else:\n",
    "            fig = ax.figure\n",
    "        ax.plot(tG, G, color=colors[1])\n",
    "        ax.plot(tG, np.exp(slopeG * tG + interceptG), '--', color=colors[1])\n",
    "        ax.plot(tR, R, color=colors[0])\n",
    "        ax.plot(tR, np.exp(slopeR * tR + interceptR), '--', color=colors[0])\n",
    "\n",
    "        ax.set(ylim=(0.9*min(G.min(), R.min()), 1.1*max(G.max(), R.max())), xlabel='Time (hour)', ylabel='log OD', yscale='log')\n",
    "        ax.text(0.5, 0.8*R.max(), ('$r_G={:.2g}$'+'\\n'+'$r_R={:.2g}$').format(slopeG, slopeR))\n",
    "        fig.tight_layout()\n",
    "        sns.despine()\n",
    "        return slopeG, interceptG, slopeR, interceptR, fig, ax \n",
    "    return slopeG, interceptG, slopeR, interceptR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = len(datasets)\n",
    "fig, ax = plt.subplots(1, cols, sharex=False, sharey=False, figsize=(width * cols, height))\n",
    "for i,(name, ds) in enumerate(datasets.items()):\n",
    "    ds['slopeG'], ds['interceptG'], ds['slopeR'], ds['interceptR'], _, _  = expnential_model(ds['model_G'], ds['model_R'], ax=ax[i], PLOT=True)    \n",
    "    ax[i].set(title=name, xlabel='')\n",
    "    if i == 0:\n",
    "        ax[i].set(ylabel=r'Log Density ($OD_{600}$)')\n",
    "    else:\n",
    "        ax[i].set(ylabel='')\n",
    "fig_xlabel('Time (hr)')\n",
    "fig.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds in datasets.values():\n",
    "    ds['flow_mean_df'] = pd.read_csv(ds['flow_mean_file'])\n",
    "    ds['flow_std_df'] = pd.read_csv(ds['flow_std_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(curveball.competitions)\n",
    "ode = curveball.competitions.baranyi_roberts_yr\n",
    "\n",
    "for ds in datasets.values():\n",
    "    K = ds['model_G'].best_values['K'], ds['model_R'].best_values['K']\n",
    "    r = ds['model_G'].best_values['r'], ds['model_R'].best_values['r']\n",
    "    nu = ds['model_G'].best_values.get('nu',1), ds['model_R'].best_values.get('nu',1)\n",
    "    q0 = ds['model_G'].best_values.get('q0', np.inf), ds['model_R'].best_values.get('q0', np.inf)\n",
    "    v = ds['model_G'].best_values.get('v', r[0]), ds['model_R'].best_values.get('v', r[1])\n",
    "    y0 = ds['model_G'].best_values['y0']/2, ds['model_R'].best_values['y0']/2\n",
    "\n",
    "    f0 = np.array(ds['flow_mean_df'][ds['flow_mean_df'].time==ds['flow_mean_df'].time.min()].weight) # initial frequencies from flow data\n",
    "    RG_model = np.unique(ds['model_RG'].best_fit) # expected initial mixed culture OD from mixed culture model\n",
    "    RG_mean = ds['dfRG'].groupby('Time').OD.mean().as_matrix()\n",
    "    RG_std = ds['dfRG'].groupby('Time').OD.std().as_matrix()\n",
    "    RG_t = np.unique(ds['dfRG'].Time)\n",
    "    G0, R0 = f0 * RG_model.min() # expected initial OD of each strain in mixed culture\n",
    "\n",
    "    t, y, a = curveball.competitions.fit_and_compete(\n",
    "        ds['model_G'], \n",
    "        ds['model_R'], \n",
    "        ds['dfRG'],\n",
    "        ode=ode,\n",
    "        y0=(G0, R0),\n",
    "        aguess=(1,1),\n",
    "        PLOT=False,\n",
    "        fixed=False\n",
    "    )\n",
    "    MRSE = ((odeint(ode, (G0, R0), RG_t, args=(K, r, nu, q0, v, a)).sum(axis=1) - RG_mean)**2).mean()\n",
    "    \n",
    "    ds['RG_model'] = RG_model\n",
    "    ds['RG_mean'] = RG_mean\n",
    "    ds['RG_std'] = RG_std\n",
    "    ds['RG_t'] = RG_t\n",
    "    ds['predicted_t'] = t\n",
    "    ds['predicted_y'] = y\n",
    "    ds['MRSE'] = MRSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = 2#len(datasets)\n",
    "cols = 2\n",
    "fig, ax = plt.subplots(rows, cols, sharex=True, sharey=False, figsize=(width * cols, height * rows))\n",
    "ax.resize((rows, cols))\n",
    "for row,(name, ds) in enumerate(datasets.items()):\n",
    "    if row >= rows:\n",
    "        break\n",
    "\n",
    "    \n",
    "    RG_model = ds['RG_model']\n",
    "    RG_mean = ds['RG_mean']\n",
    "    RG_std = ds['RG_std']\n",
    "    RG_t = ds['RG_t']\n",
    "    t = ds['predicted_t']\n",
    "    y = ds['predicted_y']\n",
    "    MRSE = ds['MRSE']\n",
    "    \n",
    "    ysum = y.sum(axis=1)\n",
    "    p1 = y[:, 0] / ysum\n",
    "    p2 = y[:, 1] / ysum\n",
    "    \n",
    "    ax[row, 0].plot(t, y[:, 0], color=green)\n",
    "    ax[row, 0].plot(t, y[:, 1], color=red)\n",
    "    ax[row, 0].plot(t, ysum, color=blue)\n",
    "    ax[row, 0].errorbar(RG_t, RG_mean, RG_std, fmt='o', color=blue)\n",
    "    \n",
    "    ax[row, 0].set(\n",
    "        xlabel='Time (hour)', \n",
    "        ylabel='OD', \n",
    "        xlim=(-0.5, t.max() + 0.5),\n",
    "        ylim=(0, 1.1*RG_model.max()),\n",
    "        title=\"MRSE: {:.2g}\".format(MRSE)\n",
    "    )\n",
    "\n",
    "    ax[row, 1].plot(t, p1, color=green)\n",
    "    ax[row, 1].plot(t, p2, color=red)\n",
    "    idx = ds['flow_mean_df'].Strain == 'Green'\n",
    "    g0 = ds['flow_mean_df'][idx].weight.max()\n",
    "    ax[row, 1].errorbar(\n",
    "        ds['flow_mean_df'][idx].time, \n",
    "        ds['flow_mean_df'][idx].weight.as_matrix(), \n",
    "        ds['flow_std_df'][idx].weight.as_matrix(), \n",
    "        marker='o', \n",
    "        ls='', \n",
    "        color=green\n",
    "    )\n",
    "    idx = ds['flow_mean_df'].Strain == 'Red'\n",
    "    r0 = ds['flow_mean_df'][idx].weight.min()\n",
    "    ax[row, 1].errorbar(\n",
    "        ds['flow_mean_df'][idx].time, \n",
    "        ds['flow_mean_df'][idx].weight.as_matrix(), \n",
    "        ds['flow_std_df'][idx].weight.as_matrix(), \n",
    "        marker='o', \n",
    "        ls='', \n",
    "        color=red\n",
    "    )    \n",
    "    ax[row, 1].set(\n",
    "        xlabel='Time (hour)', \n",
    "        ylabel='Frequency',\n",
    "        #xlim=(-0.5, t.max() + 0.5), \n",
    "        xlim=(0, ds['flow_mean_df'][idx].time.max() + 0.5),\n",
    "        ylim=(0, 1),\n",
    "        title=\"a1={:.2g}, a2={:.2g}\".format(*a)\n",
    "    )\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "# Nexp = G0*np.exp(slopeG * t), R0*np.exp(slopeR * t)\n",
    "# Bexp = Nexp[0] + Nexp[1]\n",
    "# pGexp = Nexp[0]/Bexp\n",
    "# pRexp = Nexp[1]/Bexp\n",
    "# ax[0].plot(t, Bexp, 'k--')\n",
    "# ax[1].plot(t, pGexp, '--k')\n",
    "# ax[1].plot(t, pRexp, '--k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
